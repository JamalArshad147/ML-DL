{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664a9dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from spacy import displacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126562c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "bbc = pd.read_csv('./datasets/bbc_news.csv')\n",
    "# bbc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7148ee0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e587d303",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0decac47",
   "metadata": {},
   "outputs": [],
   "source": [
    "title  = pd.DataFrame(bbc['title'])\n",
    "title.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ca4a3e",
   "metadata": {},
   "source": [
    "**Clean Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de98e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase\n",
    "title['lower'] = title['title'].str.lower()\n",
    "title.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c81b5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords\n",
    "en_stopwords = stopwords.words('english')\n",
    "title['no_stopwords'] = title['lower'].apply(lambda x: \" \".join([word for word in x.split() if word not in (en_stopwords)]))\n",
    "title.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4447ddd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# punctuation remove\n",
    "title['no_stopwords_no_punctuations'] = title.apply(lambda x: re.sub(r\"[^\\w\\s]\", '', x['no_stopwords']), axis=1)\n",
    "title.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a24f16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize\n",
    "\n",
    "title['tokenize'] = title.apply(lambda x: word_tokenize(x['no_stopwords_no_punctuations']), axis=1) # why use axis?\n",
    "# title.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ca7062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "title['lemmatised'] = title['tokenize'].apply(lambda tokens: [lemmatizer.lemmatize(token) for token in tokens])\n",
    "title.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d5bd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_new_list = sum(title['tokenize'], []) # What?\n",
    "token_clean_list = sum(title['lemmatised'], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb56a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc642fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_doc = nlp(\" \".join(token_new_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9742ee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = pd.DataFrame(columns=['token', 'pos_tag'])\n",
    "for token in spacy_doc:\n",
    "    pos_df = pd.concat([pos_df, pd.DataFrame.from_records([{'token': token.text, 'pos_tag': token.pos_}])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fe57dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df_counts = pos_df.groupby(['token', 'pos_tag']).size().reset_index(name='counts').sort_values(by='counts', ascending=False)\n",
    "pos_df_counts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ff9269",
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = pos_df_counts[pos_df_counts['pos_tag']=='NOUN'][0:10]\n",
    "nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c616a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "verb = pos_df_counts[pos_df_counts['pos_tag']=='VERB'][0:10]\n",
    "verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca40d340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NER\n",
    "ner_df = pd.DataFrame(columns=['token', 'ner_tag'])\n",
    "\n",
    "for token in spacy_doc.ents:\n",
    "    if pd.isna(token.label_) is False:\n",
    "        ner_df = pd.concat([ner_df, pd.DataFrame.from_records([{'token': token.text, 'ner_tag': token.label_}])], ignore_index=True)\n",
    "        # ner_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10faa84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import these at the top of your notebook\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# ... your other code to create spacy_doc ...\n",
    "\n",
    "# Tell displacy not to auto-render, and just return the HTML\n",
    "html = displacy.render(spacy_doc, style='ent', jupyter=False)\n",
    "\n",
    "# Now, manually display the HTML string\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da0c49a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
